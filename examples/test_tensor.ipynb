{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from core.tensor_factorization_methods.tensor_factorization_model import TensorRecommender\n",
    "from core import MAIN_DIRECTORY, DATA_CLEAN_PATH, RES_PATH, SEED, TEST_K\n",
    "from utils.evaluation import get_test_results, write_results_to_excel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all feature\n",
      "(2899, 10576)\n",
      "no text\n",
      "(2899, 2981)\n",
      "only text\n",
      "(2899, 10494)\n",
      "no feature\n",
      "(2899, 2899)\n"
     ]
    }
   ],
   "source": [
    "data = 'adobe_core5'\n",
    "\n",
    "print('all feature')\n",
    "rec = TensorRecommender(data, DATA_CLEAN_PATH, use_text_feature=True, use_no_feature=False, use_only_text=False)\n",
    "print(rec.item_feature.shape)\n",
    "print('no text')\n",
    "rec = TensorRecommender(data, DATA_CLEAN_PATH, use_text_feature=False, use_no_feature=False, use_only_text=False)\n",
    "print(rec.item_feature.shape)\n",
    "print('only text')\n",
    "rec = TensorRecommender(data, DATA_CLEAN_PATH, use_text_feature=True, use_no_feature=False, use_only_text=True)\n",
    "print(rec.item_feature.shape)\n",
    "print('no feature')\n",
    "rec = TensorRecommender(data, DATA_CLEAN_PATH, use_text_feature=False, use_no_feature=True, use_only_text=False)\n",
    "print(rec.item_feature.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperparameters with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
    "\n",
    "space = {\n",
    "    'user_item_k': hp.quniform('user_item_k', 20, 200, 1),\n",
    "    'item_time_k': hp.quniform('item_time_k', 20, 200, 1),\n",
    "    'batch_size': hp.choice('batch_size', [64, 128, 256, 512]),\n",
    "    'lr': hp.loguniform('lr', np.log(0.00001), np.log(0.1)), \n",
    "    'lambda_c': hp.loguniform('lambda_c', np.log(0.00001), np.log(10)), \n",
    "    'lambda_r': hp.quniform('lambda_r', 0.1, 1.5, 0.1),\n",
    "    'n_neg': hp.quniform('n_neg', 4, 8, 1)\n",
    "}\n",
    "\n",
    "def tune_tensor(data,\n",
    "    use_text_feature=True,\n",
    "    use_no_feature=False, \n",
    "    use_only_text=False, \n",
    "    tune_res_path=os.path.join(RES_PATH, 'tensor_recommender_tuning_results.txt'),\n",
    "    test_res_path=os.path.join(RES_PATH, 'test_results_TensorRecommender.xlsx'),\n",
    "    verbose=True,\n",
    "):\n",
    "    rec = TensorRecommender(data, DATA_CLEAN_PATH, \n",
    "                            use_text_feature=use_text_feature, \n",
    "                            use_no_feature=use_no_feature,\n",
    "                            use_only_text=use_only_text)\n",
    "    print(rec.item_feature.shape)\n",
    "    \n",
    "    def objective(params):\n",
    "        try:\n",
    "            rec.train_model(**params, early_stopping=True, verbose=verbose)\n",
    "            return {\n",
    "                'loss':-rec.params['best_eval_score'], \n",
    "                'status':STATUS_OK,\n",
    "                'best_epoch': rec.params['best_epoch']\n",
    "            }\n",
    "        except: # model training fail\n",
    "            return {\n",
    "                'loss':0,\n",
    "                'status':STATUS_FAIL,\n",
    "                'best_epoch': 0\n",
    "            }\n",
    "\n",
    "    print('Tuning hyperparameters of Tensor Recommender on dataset {}...'.format(data))\n",
    "    print(f'use_text_feature={use_text_feature}, use_no_feature={use_no_feature}, use_only_text={use_only_text}')\n",
    "    trials = Trials()\n",
    "    trials._random_state = np.random.RandomState(SEED)\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "    # save result\n",
    "    if os.path.exists(tune_res_path):\n",
    "        f = open(tune_res_path, 'a')\n",
    "    else:\n",
    "        f = open(tune_res_path, 'w')\n",
    "\n",
    "    print(f'Tensor Recommender tuning results on dataset {data}', file=f)\n",
    "    print(f'with use_text_feature={use_text_feature} and use_no_feature={use_no_feature} and use_only_text={use_only_text}...', \n",
    "    file=f)\n",
    "    \n",
    "    # get the best trial information\n",
    "    best_trial_idx = np.argmin([trial_info['result']['loss'] for trial_info in trials.trials])\n",
    "\n",
    "    optimal_params = {\n",
    "        'user_item_k': trials.trials[best_trial_idx]['misc']['vals']['user_item_k'][0],\n",
    "        'item_time_k': trials.trials[best_trial_idx]['misc']['vals']['item_time_k'][0],\n",
    "        'batch_size': [64, 128, 256, 512][trials.trials[best_trial_idx]['misc']['vals']['batch_size'][0]],\n",
    "        'lr': trials.trials[best_trial_idx]['misc']['vals']['lr'][0],\n",
    "        'lambda_c': trials.trials[best_trial_idx]['misc']['vals']['lambda_c'][0],\n",
    "        'lambda_r': trials.trials[best_trial_idx]['misc']['vals']['lambda_r'][0],\n",
    "        'n_neg': trials.trials[best_trial_idx]['misc']['vals']['n_neg'][0],\n",
    "        'n_epochs': trials.trials[best_trial_idx]['result']['best_epoch']\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        'The optimal hyperparamters are: \\n user_item_k={}, item_time_k={}, batch_size={}, lr={}, lambda_c={}, lambda_r={}, n_neg={}, n_epochs={}'.format(\n",
    "            optimal_params['user_item_k'], optimal_params['item_time_k'], \n",
    "            optimal_params['batch_size'], optimal_params['lr'], \n",
    "            optimal_params['lambda_c'], optimal_params['lambda_r'], optimal_params['n_neg'],optimal_params['n_epochs'],\n",
    "        ),\n",
    "    file=f\n",
    "    )\n",
    "    best_score = trials.trials[best_trial_idx]['result']['loss']\n",
    "    print('Best validation NDCG@10 = {}'.format(best_score), file=f)\n",
    "\n",
    "    # retrain the model\n",
    "    print('Retraining model using the optimal params...', file=f)\n",
    "    rec.train_model(**optimal_params, early_stopping=False, verbose=verbose)\n",
    "    print(f'Validation NDCG@10 of the retrained model = {rec.get_validation_ndcg()}', file=f)\n",
    "\n",
    "    # print test metrics\n",
    "    print('Test results of the retrained model:', file=f)\n",
    "    test_res = get_test_results(rec, TEST_K)\n",
    "    print(test_res, file=f)\n",
    "    \n",
    "    if use_no_feature:\n",
    "        sheet_name = data+'_nofeature'\n",
    "    elif use_text_feature:\n",
    "        if use_only_text:\n",
    "            sheet_name = data+'_onlytext'\n",
    "        else:\n",
    "            sheet_name = data\n",
    "    else:\n",
    "        sheet_name = data+'_notext'\n",
    "    \n",
    "    write_results_to_excel(test_res, test_res_path, sheet_name)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_tensor('movielens_100k', use_text_feature=True, use_no_feature=False, use_only_text=False)\n",
    "# all feature\n",
    "\n",
    "tune_tensor('movielens_100k', use_text_feature=False, use_no_feature=True, use_only_text=False)\n",
    "# no feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adobe_core5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
    "\n",
    "space = {\n",
    "    'user_item_k': hp.quniform('user_item_k', 20, 200, 1),\n",
    "    'item_time_k': hp.quniform('item_time_k', 20, 200, 1),\n",
    "    'batch_size': hp.choice('batch_size', [256, 512, 1024, 2048]),\n",
    "    'lr': hp.loguniform('lr', np.log(0.00001), np.log(0.1)), \n",
    "    'lambda_c': hp.loguniform('lambda_c', np.log(0.00001), np.log(10)), \n",
    "    'lambda_r': hp.quniform('lambda_r', 0.1, 1.5, 0.1),\n",
    "    'n_neg': hp.quniform('n_neg', 4, 8, 1)\n",
    "}\n",
    "\n",
    "def tune_tensor(data,\n",
    "    use_text_feature=True,\n",
    "    use_no_feature=False,\n",
    "    use_only_text=False,\n",
    "    tune_res_path=os.path.join(RES_PATH, 'tensor_recommender_tuning_results.txt'),\n",
    "    test_res_path=os.path.join(RES_PATH, 'test_results_TensorRecommender.xlsx'),\n",
    "    verbose=True,\n",
    "):\n",
    "    rec = TensorRecommender(data, DATA_CLEAN_PATH, use_text_feature=use_text_feature,\n",
    "                            use_no_feature=use_no_feature,\n",
    "                            use_only_text=use_only_text)\n",
    "    print(rec.item_feature.shape)\n",
    "    \n",
    "    def objective(params):\n",
    "        try:\n",
    "            rec.train_model(**params, early_stopping=True, verbose=verbose)\n",
    "            return {\n",
    "                'loss':-rec.params['best_eval_score'], \n",
    "                'status':STATUS_OK,\n",
    "                'best_epoch': rec.params['best_epoch']\n",
    "            }\n",
    "        except: # model training fail\n",
    "            return {\n",
    "                'loss':0,\n",
    "                'status':STATUS_FAIL,\n",
    "                'best_epoch': 0\n",
    "            }\n",
    "\n",
    "    print('Tuning hyperparameters of Tensor Recommender on dataset {}...'.format(data))\n",
    "    print(f'use_text_feature={use_text_feature}, use_no_feature={use_no_feature}, use_only_text={use_only_text}')\n",
    "    trials = Trials()\n",
    "    trials._random_state = np.random.RandomState(SEED)\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "    # save result\n",
    "    if os.path.exists(tune_res_path):\n",
    "        f = open(tune_res_path, 'a')\n",
    "    else:\n",
    "        f = open(tune_res_path, 'w')\n",
    "\n",
    "    print(f'Tensor Recommender tuning results on dataset {data}', file=f)\n",
    "    print(f'with use_text_feature={use_text_feature} and use_no_feature={use_no_feature} and use_only_text={use_only_text}...', \n",
    "    file=f)\n",
    "    \n",
    "    # get the best trial information\n",
    "    best_trial_idx = np.argmin([trial_info['result']['loss'] for trial_info in trials.trials])\n",
    "\n",
    "    optimal_params = {\n",
    "        'user_item_k': trials.trials[best_trial_idx]['misc']['vals']['user_item_k'][0],\n",
    "        'item_time_k': trials.trials[best_trial_idx]['misc']['vals']['item_time_k'][0],\n",
    "        'batch_size': [256, 512, 1024, 2048][trials.trials[best_trial_idx]['misc']['vals']['batch_size'][0]],\n",
    "        'lr': trials.trials[best_trial_idx]['misc']['vals']['lr'][0],\n",
    "        'lambda_c': trials.trials[best_trial_idx]['misc']['vals']['lambda_c'][0],\n",
    "        'lambda_r': trials.trials[best_trial_idx]['misc']['vals']['lambda_r'][0],\n",
    "        'n_neg': trials.trials[best_trial_idx]['misc']['vals']['n_neg'][0],\n",
    "        'n_epochs': trials.trials[best_trial_idx]['result']['best_epoch']\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        'The optimal hyperparamters are: \\n user_item_k={}, item_time_k={}, batch_size={}, lr={}, lambda_c={}, lambda_r={}, n_neg={}, n_epochs={}'.format(\n",
    "            optimal_params['user_item_k'], optimal_params['item_time_k'], \n",
    "            optimal_params['batch_size'], optimal_params['lr'], \n",
    "            optimal_params['lambda_c'], optimal_params['lambda_r'], optimal_params['n_neg'],optimal_params['n_epochs'],\n",
    "        ),\n",
    "    file=f\n",
    "    )\n",
    "    best_score = trials.trials[best_trial_idx]['result']['loss']\n",
    "    print('Best validation NDCG@10 = {}'.format(best_score), file=f)\n",
    "\n",
    "    # retrain the model\n",
    "    print('Retraining model using the optimal params...', file=f)\n",
    "    rec.train_model(**optimal_params, early_stopping=False, verbose=verbose)\n",
    "    print(f'Validation NDCG@10 of the retrained model = {rec.get_validation_ndcg()}', file=f)\n",
    "\n",
    "    # print test metrics\n",
    "    print('Test results of the retrained model:', file=f)\n",
    "    test_res = get_test_results(rec, TEST_K)\n",
    "    print(test_res, file=f)\n",
    "    \n",
    "    if use_no_feature:\n",
    "        sheet_name = data+'_nofeature'\n",
    "    elif use_text_feature:\n",
    "        if use_only_text:\n",
    "            sheet_name = data+'_onlytext'\n",
    "        else:\n",
    "            sheet_name = data\n",
    "    else:\n",
    "        sheet_name = data+'_notext'\n",
    "    \n",
    "    write_results_to_excel(test_res, test_res_path, sheet_name)\n",
    "\n",
    "    # # save the model\n",
    "    # print('Saving the retrained model...')\n",
    "    # model_info = {'model': rec.model, 'params': optimal_params}\n",
    "    # with open(os.path.join(SAVEMODEL_PATH, f'bivae_{data}.pkl'), 'wb') as flp:\n",
    "    #     pickle.dump(model_info, flp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # print('Model saved. ')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_tensor('adobe_core5', use_text_feature=False, use_no_feature=False, use_only_text=False)\n",
    "# no text\n",
    "tune_tensor('adobe_core5', use_text_feature=True, use_no_feature=False, use_only_text=False)\n",
    "# all feature\n",
    "tune_tensor('adobe_core5', use_text_feature=True, use_no_feature=False, use_only_text=True)\n",
    "# only text\n",
    "tune_tensor('adobe_core5', use_text_feature=False, use_no_feature=True, use_only_text=False)\n",
    "# no feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
